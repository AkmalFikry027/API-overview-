{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Nano Banana image generation**\n",
        "\n",
        "Nano Banana is the name for Gemini's native image generation capabilities. Gemini can generate and process images conversationally with text, images, or a combination of both.\n",
        "\n",
        "* Nano Banana: The Gemini 2.5 Flash Image model\n",
        "\n",
        "* Nano Banana: The Gemini 2.5 Flash Image model\n",
        "\n",
        "**Image generation (text-to-image)**"
      ],
      "metadata": {
        "id": "tqBZDguW8JFL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoqlAjqJ7_-Q"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from PIL import Image\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = (\"Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme\")\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-image\",\n",
        "    contents=[prompt],\n",
        ")\n",
        "\n",
        "for part in response.parts:\n",
        "    if part.text is not None:\n",
        "        print(part.text)\n",
        "    elif part.inline_data is not None:\n",
        "        image = part.as_image()\n",
        "        image.save(\"generated_image.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image editing (text-and-image-to-image)**\n",
        "\n",
        "\n",
        "Reminder: Make sure you have the necessary rights to any images you upload. Don't generate content that infringe on others' rights, including videos or images that deceive, harass, or harm."
      ],
      "metadata": {
        "id": "5xbGevWS8jaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from PIL import Image\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = (\n",
        "    \"Create a picture of my cat eating a nano-banana in a \"\n",
        "    \"fancy restaurant under the Gemini constellation\",\n",
        ")\n",
        "\n",
        "image = Image.open(\"/path/to/cat_image.png\")\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-image\",\n",
        "    contents=[prompt, image],\n",
        ")\n",
        "\n",
        "for part in response.parts:\n",
        "    if part.text is not None:\n",
        "        print(part.text)\n",
        "    elif part.inline_data is not None:\n",
        "        image = part.as_image()\n",
        "        image.save(\"generated_image.png\")"
      ],
      "metadata": {
        "id": "anBE3BKV8Bf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Multi-turn image editing**\n",
        "\n",
        "\n",
        "Keep generating and editing images conversationally. Chat or multi-turn conversation is the recommended way to iterate on images"
      ],
      "metadata": {
        "id": "m0AdXm4u9CeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=\"gemini-3-pro-image-preview\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        response_modalities=['TEXT', 'IMAGE'],\n",
        "        tools=[{\"google_search\": {}}]\n",
        "    )\n",
        ")\n",
        "\n",
        "message = \"Create a vibrant infographic that explains photosynthesis as if it were a recipe for a plant's favorite food. Show the \\\"ingredients\\\" (sunlight, water, CO2) and the \\\"finished dish\\\" (sugar/energy). The style should be like a page from a colorful kids' cookbook, suitable for a 4th grader.\"\n",
        "\n",
        "response = chat.send_message(message)\n",
        "\n",
        "for part in response.parts:\n",
        "    if part.text is not None:\n",
        "        print(part.text)\n",
        "    elif image:= part.as_image():\n",
        "        image.save(\"photosynthesis.png\")"
      ],
      "metadata": {
        "id": "EL_cM-D08Bdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate videos with Veo 3.1 in Gemini API\n",
        "\n",
        "Veo 3.1 is Google's state-of-the-art model for generating high-fidelity, 8-second 720p or 1080p videos featuring stunning realism and natively generated audio. You can access this model programmatically using the Gemini API.\n"
      ],
      "metadata": {
        "id": "9SoyV_kO9QoL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text to video generation**"
      ],
      "metadata": {
        "id": "MvFAMO5C9jZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = \"\"\"A close up of two people staring at a cryptic drawing on a wall, torchlight flickering.\n",
        "A man murmurs, 'This must be it. That's the secret code.' The woman looks at him and whispering excitedly, 'What did you find?'\"\"\"\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=\"veo-3.1-generate-preview\",\n",
        "    prompt=prompt,\n",
        ")\n",
        "\n",
        "# Poll the operation status until the video is ready.\n",
        "while not operation.done:\n",
        "    print(\"Waiting for video generation to complete...\")\n",
        "    time.sleep(10)\n",
        "    operation = client.operations.get(operation)\n",
        "\n",
        "# Download the generated video.\n",
        "generated_video = operation.response.generated_videos[0]\n",
        "client.files.download(file=generated_video.video)\n",
        "generated_video.video.save(\"dialogue_example.mp4\")\n",
        "print(\"Generated video saved to dialogue_example.mp4\")"
      ],
      "metadata": {
        "id": "N0Xeakn28BbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image to video generation**"
      ],
      "metadata": {
        "id": "FuY95MPv-EL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = \"Panning wide shot of a calico kitten sleeping in the sunshine\"\n",
        "\n",
        "# Step 1: Generate an image with Nano Banana.\n",
        "image = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash-image\",\n",
        "    contents=prompt,\n",
        "    config={\"response_modalities\":['IMAGE']}\n",
        ")\n",
        "\n",
        "# Step 2: Generate video with Veo 3.1 using the image.\n",
        "operation = client.models.generate_videos(\n",
        "    model=\"veo-3.1-generate-preview\",\n",
        "    prompt=prompt,\n",
        "    image=image.parts[0].as_image(),\n",
        ")\n",
        "\n",
        "# Poll the operation status until the video is ready.\n",
        "while not operation.done:\n",
        "    print(\"Waiting for video generation to complete...\")\n",
        "    time.sleep(10)\n",
        "    operation = client.operations.get(operation)\n",
        "\n",
        "# Download the video.\n",
        "video = operation.response.generated_videos[0]\n",
        "client.files.download(file=video.video)\n",
        "video.video.save(\"veo3_with_image_input.mp4\")\n",
        "print(\"Generated video saved to veo3_with_image_input.mp4\")"
      ],
      "metadata": {
        "id": "dUeySTGc8BYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using reference images**\n",
        "\n",
        "now accepts up to 3 reference images to guide your generated video's content. Provide images of a person, character, or product to preserve the subject's appearance in the output video."
      ],
      "metadata": {
        "id": "lDg6Hc0g-LZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = \"The video opens with a medium, eye-level shot of a beautiful woman with dark hair and warm brown eyes. She wears a magnificent, high-fashion flamingo dress with layers of pink and fuchsia feathers, complemented by whimsical pink, heart-shaped sunglasses. She walks with serene confidence through the crystal-clear, shallow turquoise water of a sun-drenched lagoon. The camera slowly pulls back to a medium-wide shot, revealing the breathtaking scene as the dress's long train glides and floats gracefully on the water's surface behind her. The cinematic, dreamlike atmosphere is enhanced by the vibrant colors of the dress against the serene, minimalist landscape, capturing a moment of pure elegance and high-fashion fantasy.\"\n",
        "\n",
        "dress_reference = types.VideoGenerationReferenceImage(\n",
        "  image=dress_image, # Generated separately with Nano Banana\n",
        "  reference_type=\"asset\"\n",
        ")\n",
        "\n",
        "sunglasses_reference = types.VideoGenerationReferenceImage(\n",
        "  image=glasses_image, # Generated separately with Nano Banana\n",
        "  reference_type=\"asset\"\n",
        ")\n",
        "\n",
        "woman_reference = types.VideoGenerationReferenceImage(\n",
        "  image=woman_image, # Generated separately with Nano Banana\n",
        "  reference_type=\"asset\"\n",
        ")\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=\"veo-3.1-generate-preview\",\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "      reference_images=[dress_reference, glasses_reference, woman_reference],\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Poll the operation status until the video is ready.\n",
        "while not operation.done:\n",
        "    print(\"Waiting for video generation to complete...\")\n",
        "    time.sleep(10)\n",
        "    operation = client.operations.get(operation)\n",
        "\n",
        "# Download the video.\n",
        "video = operation.response.generated_videos[0]\n",
        "client.files.download(file=video.video)\n",
        "video.video.save(\"veo3.1_with_reference_images.mp4\")\n",
        "print(\"Generated video saved to veo3.1_with_reference_images.mp4\")"
      ],
      "metadata": {
        "id": "eZcalFj58BWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using first and last frames**\n",
        "\n"
      ],
      "metadata": {
        "id": "cnao0-2s-iFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = \"A cinematic, haunting video. A ghostly woman with long white hair and a flowing dress swings gently on a rope swing beneath a massive, gnarled tree in a foggy, moonlit clearing. The fog thickens and swirls around her, and she slowly fades away, vanishing completely. The empty swing is left swaying rhythmically on its own in the eerie silence.\"\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=\"veo-3.1-generate-preview\",\n",
        "    prompt=prompt,\n",
        "    image=first_image, # Generated separately with Nano Banana\n",
        "    config=types.GenerateVideosConfig(\n",
        "      last_frame=last_image # Generated separately with Nano Banana\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Poll the operation status until the video is ready.\n",
        "while not operation.done:\n",
        "    print(\"Waiting for video generation to complete...\")\n",
        "    time.sleep(10)\n",
        "    operation = client.operations.get(operation)\n",
        "\n",
        "# Download the video.\n",
        "video = operation.response.generated_videos[0]\n",
        "client.files.download(file=video.video)\n",
        "video.video.save(\"veo3.1_with_interpolation.mp4\")\n",
        "print(\"Generated video saved to veo3.1_with_interpolation.mp4\")"
      ],
      "metadata": {
        "id": "tNzuWTY08BTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input video limitations:\n",
        "\n",
        "* Veo-generated videos only up to 141 seconds long.\n",
        "\n",
        "* Gemini API only supports video extensions for Veo-generated videos.\n",
        "\n",
        "* The video should come from a previous generation, like operation.response.generated_videos[0].video\n",
        "\n",
        "\n",
        "* Input videos are expected to have a certain length, aspect ratio, and dimensions:\n",
        "    * Aspect ratio: 9:16 or 16:9\n",
        "    * Resolution: 720p\n",
        "    * Video length: 141 seconds or less\n",
        "    \n",
        "The output of the extension is a single video combining the user input video and the generated extended video for up to 148 seconds of video."
      ],
      "metadata": {
        "id": "lrH7h31N-nvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "prompt = \"Track the butterfly into the garden as it lands on an orange origami flower. A fluffy white puppy runs up and gently pats the flower.\"\n",
        "\n",
        "operation = client.models.generate_videos(\n",
        "    model=\"veo-3.1-generate-preview\",\n",
        "    video=operation.response.generated_videos[0].video, # This must be a video from a previous generation\n",
        "    prompt=prompt,\n",
        "    config=types.GenerateVideosConfig(\n",
        "        number_of_videos=1,\n",
        "        resolution=\"720p\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Poll the operation status until the video is ready.\n",
        "while not operation.done:\n",
        "    print(\"Waiting for video generation to complete...\")\n",
        "    time.sleep(10)\n",
        "    operation = client.operations.get(operation)\n",
        "\n",
        "# Download the video.\n",
        "video = operation.response.generated_videos[0]\n",
        "client.files.download(file=video.video)\n",
        "video.video.save(\"veo3.1_extension.mp4\")\n",
        "print(\"Generated video saved to veo3.1_extension.mp4\")"
      ],
      "metadata": {
        "id": "GqBPYKOu8BRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
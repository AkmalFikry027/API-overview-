{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **How to call the Interactions API with a text prompt**"
      ],
      "metadata": {
        "id": "VevVPwVTeS7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction =  client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Tell me a short joke about programming.\"\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "aSGpH2QeGaMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic interactions**"
      ],
      "metadata": {
        "id": "YkEuYaYOegHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction =  client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Tell me a short joke about programming.\"\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "R6fVMFMnGaJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversation\n",
        "\n",
        "You can build multi-turn conversations in two ways:\n",
        "\n",
        "* Statefully by referencing a previous interaction\n",
        "\n",
        "* Statelessly by providing the entire conversation history\n",
        "\n",
        "**Stateful conversation**\n",
        "\n",
        "Pass the id from the previous interaction to the previous_interaction_id parameter to continue a conversation."
      ],
      "metadata": {
        "id": "hgFemZw4emzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# 1. First turn\n",
        "interaction1 = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Hi, my name is Phil.\"\n",
        ")\n",
        "print(f\"Model: {interaction1.outputs[-1].text}\")\n",
        "\n",
        "# 2. Second turn (passing previous_interaction_id)\n",
        "interaction2 = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"What is my name?\",\n",
        "    previous_interaction_id=interaction1.id\n",
        ")\n",
        "print(f\"Model: {interaction2.outputs[-1].text}\")"
      ],
      "metadata": {
        "id": "jDg3pTfvGaGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal capabilities\n",
        "\n",
        "You can use the Interactions API for multimodal use cases such as image understanding or video generation.\n",
        "\n",
        "**Multimodal understanding**\n",
        "\n",
        "\n",
        "You can provide multimodal data as base64 encoded data inline or using the Files API for larger files.\n",
        "\n",
        "Image understanding\n"
      ],
      "metadata": {
        "id": "oG-nDTcsfBdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# Read and encode the image\n",
        "with open(Path(__file__).parent / \"car.png\", \"rb\") as f:\n",
        "    base64_image = base64.b64encode(f.read()).decode('utf-8')\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=[\n",
        "        {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
        "        {\"type\": \"image\", \"data\": base64_image, \"mime_type\": \"image/png\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "ptWyAXG1GaDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio understanding"
      ],
      "metadata": {
        "id": "ZlzkKD4wfRtD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# Read and encode the audio\n",
        "with open(Path(__file__).parent / \"speech.wav\", \"rb\") as f:\n",
        "    base64_audio = base64.b64encode(f.read()).decode('utf-8')\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=[\n",
        "        {\"type\": \"text\", \"text\": \"What does this audio say?\"},\n",
        "        {\"type\": \"audio\", \"data\": base64_audio, \"mime_type\": \"audio/wav\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "We5JEkIqGaA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video understanding"
      ],
      "metadata": {
        "id": "NMXT3CLbfWGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# Read and encode the video\n",
        "with open(Path(__file__).parent / \"video.mp4\", \"rb\") as f:\n",
        "    base64_video = base64.b64encode(f.read()).decode('utf-8')\n",
        "\n",
        "print(\"Analyzing video...\")\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=[\n",
        "        {\"type\": \"text\", \"text\": \"What is happening in this video? Provide a timestamped summary.\"},\n",
        "        {\"type\": \"video\", \"data\": base64_video, \"mime_type\": \"video/mp4\" }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "9JKaGYT3GZ9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Document (PDF) understanding"
      ],
      "metadata": {
        "id": "ErQYayjDgFTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "with open(\"sample.pdf\", \"rb\") as f:\n",
        "    base64_pdf = base64.b64encode(f.read()).decode('utf-8')\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=[\n",
        "        {\"type\": \"text\", \"text\": \"What is this document about?\"},\n",
        "        {\"type\": \"document\", \"data\": base64_pdf, \"mime_type\": \"application/pdf\"}\n",
        "    ]\n",
        ")\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "gkGC5hBGGZ7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multimodal generation\n",
        "\n",
        "\n",
        "You can use Interactions API to generate multimodal outputs.\n",
        "\n",
        "Image generation"
      ],
      "metadata": {
        "id": "o_vn-6Zdgkkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-pro-image-preview\",\n",
        "    input=\"Generate an image of a futuristic city.\",\n",
        "    response_modalities=[\"IMAGE\"]\n",
        ")\n",
        "\n",
        "for output in interaction.outputs:\n",
        "    if output.type == \"image\":\n",
        "        print(f\"Generated image with mime_type: {output.mime_type}\")\n",
        "        # Save the image\n",
        "        with open(\"generated_city.png\", \"wb\") as f:\n",
        "            f.write(base64.b64decode(output.data))"
      ],
      "metadata": {
        "id": "-djLESGeGZ5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agentic capabilities\n",
        "\n",
        "The Interactions API is designed for building and interacting with agents, and includes support for function calling, built-in tools, structured outputs, and the Model Context Protocol (MCP).\n",
        "\n",
        "## Agents\n",
        "\n",
        "You can use specialized agents like deep-research-pro-preview-12-2025 for complex tasks. To learn more about the Gemini Deep Research Agent, see the Deep Research guide."
      ],
      "metadata": {
        "id": "s08aDYmshjg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# 1. Start the Deep Research Agent\n",
        "initial_interaction = client.interactions.create(\n",
        "    input=\"Research the history of the Google TPUs with a focus on 2025 and 2026.\",\n",
        "    agent=\"deep-research-pro-preview-12-2025\",\n",
        "    background=True\n",
        ")\n",
        "\n",
        "print(f\"Research started. Interaction ID: {initial_interaction.id}\")\n",
        "\n",
        "# 2. Poll for results\n",
        "while True:\n",
        "    interaction = client.interactions.get(initial_interaction.id)\n",
        "    print(f\"Status: {interaction.status}\")\n",
        "\n",
        "    if interaction.status == \"completed\":\n",
        "        print(\"\\nFinal Report:\\n\", interaction.outputs[-1].text)\n",
        "        break\n",
        "    elif interaction.status in [\"failed\", \"cancelled\"]:\n",
        "        print(f\"Failed with status: {interaction.status}\")\n",
        "        break\n",
        "\n",
        "    time.sleep(10)"
      ],
      "metadata": {
        "id": "AkW5-nz1GZ2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools and function calling\n",
        "\n",
        "\n",
        "This section explains how to use function calling to define custom tools and how to use Google's built-in tools within the Interactions API.\n",
        "\n",
        "**Function calling**"
      ],
      "metadata": {
        "id": "XZRSgz8xh5kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "# 1. Define the tool\n",
        "def get_weather(location: str):\n",
        "    \"\"\"Gets the weather for a given location.\"\"\"\n",
        "    return f\"The weather in {location} is sunny.\"\n",
        "\n",
        "weather_tool = {\n",
        "    \"type\": \"function\",\n",
        "    \"name\": \"get_weather\",\n",
        "    \"description\": \"Gets the weather for a given location.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"location\": {\"type\": \"string\", \"description\": \"The city and state, e.g. San Francisco, CA\"}\n",
        "        },\n",
        "        \"required\": [\"location\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "# 2. Send the request with tools\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"What is the weather in Paris?\",\n",
        "    tools=[weather_tool]\n",
        ")\n",
        "\n",
        "# 3. Handle the tool call\n",
        "for output in interaction.outputs:\n",
        "    if output.type == \"function_call\":\n",
        "        print(f\"Tool Call: {output.name}({output.arguments})\")\n",
        "        # Execute tool\n",
        "        result = get_weather(**output.arguments)\n",
        "\n",
        "        # Send result back\n",
        "        interaction = client.interactions.create(\n",
        "            model=\"gemini-3-flash-preview\",\n",
        "            previous_interaction_id=interaction.id,\n",
        "            input=[{\n",
        "                \"type\": \"function_result\",\n",
        "                \"name\": output.name,\n",
        "                \"call_id\": output.id,\n",
        "                \"result\": result\n",
        "            }]\n",
        "        )\n",
        "        print(f\"Response: {interaction.outputs[-1].text}\")"
      ],
      "metadata": {
        "id": "lqzgK9FYGZz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function calling with client-side state**\n",
        "\n",
        "If you don't want to use server-side state, you can manage it all on the client side."
      ],
      "metadata": {
        "id": "nwYpvZEninSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "client = genai.Client()\n",
        "\n",
        "functions = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"name\": \"schedule_meeting\",\n",
        "        \"description\": \"Schedules a meeting with specified attendees at a given time and date.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"attendees\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
        "                \"date\": {\"type\": \"string\", \"description\": \"Date of the meeting (e.g., 2024-07-29)\"},\n",
        "                \"time\": {\"type\": \"string\", \"description\": \"Time of the meeting (e.g., 15:00)\"},\n",
        "                \"topic\": {\"type\": \"string\", \"description\": \"The subject of the meeting.\"},\n",
        "            },\n",
        "            \"required\": [\"attendees\", \"date\", \"time\", \"topic\"],\n",
        "        },\n",
        "    }\n",
        "]\n",
        "\n",
        "history = [{\"role\": \"user\",\"content\": [{\"type\": \"text\", \"text\": \"Schedule a meeting for 2025-11-01 at 10 am with Peter and Amir about the Next Gen API.\"}]}]\n",
        "\n",
        "# 1. Model decides to call the function\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=history,\n",
        "    tools=functions\n",
        ")\n",
        "\n",
        "# add model interaction back to history\n",
        "history.append({\"role\": \"model\", \"content\": interaction.outputs})\n",
        "\n",
        "for output in interaction.outputs:\n",
        "    if output.type == \"function_call\":\n",
        "        print(f\"Function call: {output.name} with arguments {output.arguments}\")\n",
        "\n",
        "        # 2. Execute the function and get a result\n",
        "        # In a real app, you would call your function here.\n",
        "        # call_result = schedule_meeting(**json.loads(output.arguments))\n",
        "        call_result = \"Meeting scheduled successfully.\"\n",
        "\n",
        "        # 3. Send the result back to the model\n",
        "        history.append({\"role\": \"user\", \"content\": [{\"type\": \"function_result\", \"name\": output.name, \"call_id\": output.id, \"result\": call_result}]})\n",
        "\n",
        "        interaction2 = client.interactions.create(\n",
        "            model=\"gemini-3-flash-preview\",\n",
        "            input=history,\n",
        "        )\n",
        "        print(f\"Final response: {interaction2.outputs[-1].text}\")\n",
        "    else:\n",
        "        print(f\"Output: {output}\")"
      ],
      "metadata": {
        "id": "wA3xkei6GZxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Built-in tools\n",
        "\n",
        "Gemini comes with built-in tools like Grounding with Google Search, Code execution, and URL context.\n",
        "\n",
        "Grounding with Google search"
      ],
      "metadata": {
        "id": "sXMy1cECjB9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Who won the last Super Bowl?\",\n",
        "    tools=[{\"type\": \"google_search\"}]\n",
        ")\n",
        "# Find the text output (not the GoogleSearchResultContent)\n",
        "text_output = next((o for o in interaction.outputs if o.type == \"text\"), None)\n",
        "if text_output:\n",
        "    print(text_output.text)"
      ],
      "metadata": {
        "id": "TCjJeWCVGZux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code execution"
      ],
      "metadata": {
        "id": "-qFEqgY1jITr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Calculate the 50th Fibonacci number.\",\n",
        "    tools=[{\"type\": \"code_execution\"}]\n",
        ")\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "y37mfFjfGZsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**URL context**"
      ],
      "metadata": {
        "id": "KL5uoJOQjStf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Summarize the content of https://www.wikipedia.org/\",\n",
        "    tools=[{\"type\": \"url_context\"}]\n",
        ")\n",
        "# Find the text output (not the URLContextResultContent)\n",
        "text_output = next((o for o in interaction.outputs if o.type == \"text\"), None)\n",
        "if text_output:\n",
        "    print(text_output.text)"
      ],
      "metadata": {
        "id": "XZXZkEd5GZp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Remote Model context protocol (MCP)**\n",
        "\n",
        "Remote MCP integration simplifies agent development by allowing the Gemini API to directly call external tools hosted on remote servers"
      ],
      "metadata": {
        "id": "suct1ZuBjXdz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "mcp_server = {\n",
        "    \"type\": \"mcp_server\",\n",
        "    \"name\": \"weather_service\",\n",
        "    \"url\": \"https://gemini-api-demos.uc.r.appspot.com/mcp\"\n",
        "}\n",
        "\n",
        "today = datetime.date.today().strftime(\"%d %B %Y\")\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    input=\"What is the weather like in New York today?\",\n",
        "    tools=[mcp_server],\n",
        "    system_instruction=f\"Today is {today}.\"\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "YPd-h1_eGZnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important notes:\n",
        "\n",
        "* Remote MCP only works with Streamable HTTP servers (SSE servers are not supported)\n",
        "\n",
        "* Remote MCP does not work with Gemini 3 models (this is coming soon)\n",
        "\n",
        "* MCP server names shouldn't include \"-\" character (use snake_case server names instead)\n",
        "\n",
        "**Structured output (JSON schema)**\n",
        "\n",
        "\n",
        "Enforce a specific JSON output by providing a JSON schema in the response_format parameter. This is useful for tasks like moderation, classification, or data extraction."
      ],
      "metadata": {
        "id": "7mJpEgORkKvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Literal, Union\n",
        "client = genai.Client()\n",
        "\n",
        "class SpamDetails(BaseModel):\n",
        "    reason: str = Field(description=\"The reason why the content is considered spam.\")\n",
        "    spam_type: Literal[\"phishing\", \"scam\", \"unsolicited promotion\", \"other\"]\n",
        "\n",
        "class NotSpamDetails(BaseModel):\n",
        "    summary: str = Field(description=\"A brief summary of the content.\")\n",
        "    is_safe: bool = Field(description=\"Whether the content is safe for all audiences.\")\n",
        "\n",
        "class ModerationResult(BaseModel):\n",
        "    decision: Union[SpamDetails, NotSpamDetails]\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Moderate the following content: 'Congratulations! You've won a free cruise. Click here to claim your prize: www.definitely-not-a-scam.com'\",\n",
        "    response_format=ModerationResult.model_json_schema(),\n",
        ")\n",
        "\n",
        "parsed_output = ModerationResult.model_validate_json(interaction.outputs[-1].text)\n",
        "print(parsed_output)"
      ],
      "metadata": {
        "id": "A_pvnG4HGZlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced features\n",
        "\n",
        "There are also additional advance features that give you more flexibility in working with Interactions API.\n",
        "\n",
        "## Streaming\n",
        "\n",
        "Receive responses incrementally as they are generated."
      ],
      "metadata": {
        "id": "PculYyWelGsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "stream = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Explain quantum entanglement in simple terms.\",\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "    if chunk.event_type == \"content.delta\":\n",
        "        if chunk.delta.type == \"text\":\n",
        "            print(chunk.delta.text, end=\"\", flush=True)\n",
        "        elif chunk.delta.type == \"thought\":\n",
        "            print(chunk.delta.thought, end=\"\", flush=True)\n",
        "    elif chunk.event_type == \"interaction.complete\":\n",
        "        print(f\"\\n\\n--- Stream Finished ---\")\n",
        "        print(f\"Total Tokens: {chunk.interaction.usage.total_tokens}\")"
      ],
      "metadata": {
        "id": "lGuLkjqZGZig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration**\n",
        "\n",
        "Customize the model's behavior with generation_config"
      ],
      "metadata": {
        "id": "DzEsidUklSI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=\"Tell me a story about a brave knight.\",\n",
        "    generation_config={\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_output_tokens\": 500,\n",
        "        \"thinking_level\": \"low\",\n",
        "    }\n",
        ")\n",
        "\n",
        "print(interaction.outputs[-1].text)"
      ],
      "metadata": {
        "id": "s6y9IULKGZfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working with files**\n",
        "\n",
        "Working with remote files\n",
        "\n",
        "\n",
        "Access files using remote URLs directly in the API call.\n"
      ],
      "metadata": {
        "id": "umzLOEezl-zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "client = genai.Client()\n",
        "\n",
        "interaction = client.interactions.create(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    input=[\n",
        "        {\n",
        "            \"type\": \"image\",\n",
        "            \"uri\": \"https://github.com/<github-path>/cats-and-dogs.jpg\",\n",
        "        },\n",
        "        {\"type\": \"text\", \"text\": \"Describe what you see.\"}\n",
        "    ],\n",
        ")\n",
        "for output in interaction.outputs:\n",
        "    if output.type == \"text\":\n",
        "        print(output.text)"
      ],
      "metadata": {
        "id": "YRz81473GZdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[https://ai.google.dev/gemini-api/docs/models](https://)"
      ],
      "metadata": {
        "id": "Oiqd-sF2oWt2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gdsh_ISjl8L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3P5R3nDNl8Jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gtY1FpEAl8FZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPLlfqWhl8C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-SzKK0NRl8AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFnYIwY8l7-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dBnN9nHsl77T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
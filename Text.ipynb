{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Text\n",
        "\n",
        " The Gemini API can generate text output from various inputs, including text, images, video, and audio.\n",
        "\n",
        "Here's a basic example that takes a single text input:\n"
      ],
      "metadata": {
        "id": "0rKS9mFi5fAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text generation**\n",
        "\n"
      ],
      "metadata": {
        "id": "OzO7r6AE5Y5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"How does AI work?\"\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "JwF_T56x4C1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thinking with Gemini**\n",
        "\n",
        "Gemini models often have \"thinking\" enabled by default which allows the model to reason before responding to a request"
      ],
      "metadata": {
        "id": "1S5RMXNW5kdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"How does AI work?\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        thinking_config=types.ThinkingConfig(thinking_budget=0) # Disables thinking\n",
        "    ),\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "9wnsuIRR4Cyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**System instructions and other configurations**"
      ],
      "metadata": {
        "id": "W96uXxfh5xUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    config=types.GenerateContentConfig(\n",
        "        system_instruction=\"You are a cat. Your name is Neko.\"),\n",
        "    contents=\"Hello there\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "scs_KtWn4Cv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=[\"Explain how AI works\"],\n",
        "    config=types.GenerateContentConfig(\n",
        "        temperature=0.1\n",
        "    )\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "tXwH9zId4CtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multimodal inputs**\n",
        "\n",
        "The Gemini API supports multimodal inputs, allowing you to combine text with media files. The following example demonstrates providing an image"
      ],
      "metadata": {
        "id": "_a9_WBUr557C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "image = Image.open(\"/path/to/organ.png\")\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=[image, \"Tell me about this instrument\"]\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "M33_RO7F4Cqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Streaming responses**\n",
        "\n",
        "the model returns a response only after the entire generation process is complet"
      ],
      "metadata": {
        "id": "Uw_wredD5-_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "\n",
        "response = client.models.generate_content_stream(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=[\"Explain how AI works\"]\n",
        ")\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")"
      ],
      "metadata": {
        "id": "gC5Yfr5D4Cnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multi-turn conversations (chat)**\n",
        "\n",
        "SDKs provide functionality to collect multiple rounds of prompts and responses into a chat, giving you an easy way to keep track of the conversation history."
      ],
      "metadata": {
        "id": "tyOkVd6i6sA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
        "\n",
        "response = chat.send_message(\"I have 2 dogs in my house.\")\n",
        "print(response.text)\n",
        "\n",
        "response = chat.send_message(\"How many paws are in my house?\")\n",
        "print(response.text)\n",
        "\n",
        "for message in chat.get_history():\n",
        "    print(f'role - {message.role}',end=\": \")\n",
        "    print(message.parts[0].text)"
      ],
      "metadata": {
        "id": "Ypq6peop4Ck5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client()\n",
        "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
        "\n",
        "response = chat.send_message_stream(\"I have 2 dogs in my house.\")\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")\n",
        "\n",
        "response = chat.send_message_stream(\"How many paws are in my house?\")\n",
        "for chunk in response:\n",
        "    print(chunk.text, end=\"\")\n",
        "\n",
        "for message in chat.get_history():\n",
        "    print(f'role - {message.role}', end=\": \")\n",
        "    print(message.parts[0].text)"
      ],
      "metadata": {
        "id": "oJkQNU1w4CiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fx2P7qkA4Cfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sN7aaSUo4CdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9d9wbLzo4Cah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJFhT9M04CYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0Y6lu1O4CVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pahp6pBa4CSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KGvy3wlG4CPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kAgEpcaQ4CNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRdtthFi4CKb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}